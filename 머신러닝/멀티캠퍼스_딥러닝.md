# 딥러닝

- 통계학의 구현은 대부분 사이킷런이었으나, 신경망의 구현은 텐서플로우라는 모듈로 구현이 되어있음
- 텐서플로우는 C언어와 파이썬에서만 구현이 됨
- 딥러닝이 활성화가 된 것은 텐서플로우가 파이썬에서 구동이된 2018~2019년도 부터 임
- TensorFlow 1.X 저수준(난이도 어려움)(2020년 이전)
  - 텐서1사용
    - 저수준api사용
    - 케라스모듈 호출 사용
    - 파이토치설치후 사용(텍스트 관련 모듈은 파이토치로 제작, KOBERT)(난이도 보통)
- TensorFlow 2.X 고수준(난이도 쉬움)(2020년 이후)
  - 텐서2 사용
    - tf.keras (기능이 다양화 됨, 모든기능을 사용하도록 제공 됨)
  - 핸들링이 어려움(동작 방식을 몰라서)
- 전이학습(이미 작성되어진 모델) : 찾아서 내용 정리하기
- 이미지 분석 케라스
- CNN 텐서플로우(이미지분석)

- 배치 : 최적화된 w, b 값을 찾는것
- [미니배치](https://welcome-to-dewy-world.tistory.com/86) : 
- [텐서플로우 옵티마이저(배치)]() : 배치사이즈를 결정하고 w, b값을 업데이트 함.
  - 손실 함수을 통해 얻은 **손실값으로부터 모델을 업데이트하는 방식**을 의미
  - 머신러닝 학습 프로세스에서 실제로 파라미터를 갱신시키는 부분을 의미 [참고](https://wiserloner.tistory.com/1032)
  - 오차역전파법과 같은 방식으로, 각 파라미터의 기울기를 그라디언트로 구하여 재료를 구해왔으면, 이를 이용하여 실제 가중치 변화를 주는 부분

## 인공신경망 모델

- 활성화 함수 : x -> y 를 만들기위해 사용 되는 함수를 의미, 현재 10개 중 주로 4개가 사용됨, Y값 계산식에 사용 되는 공식을 의미

  - Dense층의 결과를 계산하는 공식임

  - 활성화함수 : 값을 예측하기 위해 사용되는 공식!

    Dense층의 결과를 계산하는 공식임

    

    

    중간 Dense는 다음Dense에 넘어가기에 적합한 중간값 (대부분 Relu라는 함수를 사용함)

    Relu(min = 0, max = max) : 0미만 -값은 0으로 0 이상의 값이면 그값그대로 출력

    

    최종 Dense는 원하는 y값을 의미함

    \- y값은 무한대의 숫자인 선형회귀이거나, 

    \> 결과는 무한대의 숫자중 1개 (활성화함수 기재안함)

    \- 0 또는 1값중 한개인 이항분류이거나, 

    \> 결과1은 0또는 1의 한개의 비트 (활성화함수 시그모이드)

    \> 결과2는 [1,0], [0,1]의 두개의 비트로 표현(활성화함수 소프트맥스)

    \- 여러개의 다항분류이거나, 무조건 분류갯수만큼 원핫인코딩함

    \> ex) 개, 고양이, 사자, 사슴 4개의 분류가있으면 개는 1, 고양이 2, 사자는 3, 사슴은 4, 개[1,0,0,0], 고양이는 [0,1,0,0] 과 같이 표현(활성화함수 소프트맥스)

- 퍼셉트론 : 인공신경망의 시초(and, or, nand, nor 가능:선형 분리는 가능하지만 XOR등의 비선형 분리는 불가능)
  - y 예측값이 임계값을 기준으로 크면 1 작으면 0으로 출력, 
  - 계단함수 : 결과 예측값이 0또는 1두개로 나오는 활성화 함수를 계단함수 라고 함
  - and 게이트 : 둘다 1이어야 1 하나라도 0이면 0
  - or 게이트 : 둘중 하나만 1이어도 1 둘다 0이면 0

- 다층 퍼셉트론(비선형 분리 가능하게 하는/ 퍼셉트론을 여러개 연결하면 비선형분리를 해결하지 않을까)
- model.get_weights() 모델의 w, b 값을 보여주는 함수

\# 오버피팅(가중치가 훈련데이터만 잘 맞는 경우)를 확인하는 방법

\# 오버피팅 해결방법 : dense수를 줄이거나, 모델의 add를 줄이거나, epochs를 줄이거나, 모델 add사이에 dropout을 넣거나(몇번 넣을지 어디에 넣을지는 자유), 배치를 크게하거나, 러닝레이트값을 크게하거나, 정답이 없음 찾아야 함

\# w, b 업데이트(갱신)은 훈련데이터하고만 작업하는 것임.

\## 훈련데이터의 loss값은 줄어드는데, 검증데이터의 loss값은 늘어나는 경우

[평균제곱오차(mse),평균절대오차(mae)]

- 실제 가격과 예측 가격의 차이가 평균적으로 2,200 달러정도 차이가 있음을 의미

- MAE와 MSE의 차이는 무엇인가?

  > MSE는 제곱을 해주고 / MAE는 제곱은 하지 않고 절대값을 구한다.

- MAE와 MSE의 공통점은 무엇인가?

  > 실제값과 측정값을 빼주는 것 평균을 내주는 것 (M - mean)

평균 제곱 오차(MSE)는 회귀에서 자주 사용되는 손실 함수입니다.
정확도 개념은 회귀에 적용되지 않습니다. 일반적인 회귀 지표는 평균 절대 오차(MAE)입니다.

> MSE는 손실함수로써 쓰이고 / MAE는 회귀지표로써 사용된다.



### 인공신경망에서 

- 하이퍼파라미터 튜닝
  1. 레이어를 몇개 쌓을것 인가?
  2. dense units의 갯수 설정
  3. dropout 설정
  4. 옵티마이저(최적화함수)
  5. 손실함수=loss 설정
  6. 러닝레이트값설정(lr=0.07) 등 (w업데이트에 사용되는 값임)
  7. 배치사이즈 설정
  8. epochs 설정
- 



## 이미지 분석

정밀도 : 정답 맞춘 갯수 / 예측 정답 갯수

재현율 : 정답 맞춘 갯수 / 실제 정답 갯수

## MNIST

- 이미지 데이터셋의 이해
  - 흑백은 2차원으로 표현 가능 (0~255로 표현 하기때문)
  - 컬러는 반드시 3차원으로 표현 해야 함(R,G,B 값을 한 칸에 넣어야 하기 때문)
- h5모델에 들어간 x자료의 특징
  1. 사이즈는 28*28
  2. 그레이스케일이다(2차원)
  3. 배경이 어둡고 내용이 밝다
  4. 0~1사이다(/255)
  5. 28*28을 (1, 784)로 변경하였다.

- 모델제작 및 불러오기

```python
# 저장
model.save('my_mnist.h5')
# 불러오기
load_model = tf.keras.models.load_model('my_mnist.h5')
```

