# 특징 공학

- 머신러닝의 특징 행렬을 구축하는데 사용할 수 있는 수치형 데이터로 변환하는 것
- 범주형 특징을 수치형 특징으로 변환(인코딩)
- 복잡도를 증가시키기 위한 유도 특징()
- 누락 데이터 대체

1. 범주 특징의 변환
   - 데이터와 값을 연결해 키를 만들어 둠
2. 텍스트 특징의 변환
   - CountVectorizer : 단어 빈도 체크
   - TfidVectorizer : 단어 빈도뿐만 아닌 중요도와 관련된 가중치를 적용한 값을 넣음
3. 유도 특징의 추가
   - LinearRegression : 고편향, 고분산 등을 확인하여 복잡도를 조절해야 함
   - PolynomialFeatures : 다항식(차수)을 추가하여  fit_transfrom 해주어 복잡도를 맞춰줌
4. 누락 데이터 대체
   - from sklearn.imputer import SimpleImpuer
     - imputer(strategy = 'mean') : 누락값 평균값으로 변경
5. 특징 파이프 라인
   - from skelearn.pipeline import make_pipeline
     - make_pipeline(imputer(startgey='mena'), PolynomialFeatures(degree=2), LinearRegression())
     - 누락값 평균으로 대체, 이차 형태의 유도특징 변환(차수로 복잡도 맞춤), 선형회귀 적합 복잡도 조절

## 주요정리

1. 교차검증을 사용하면 모델을 훈련시킬 데이터를 빠드릴 수 있는 문제를 방지할 수 있다.
2. 검증곡선을 시각화하면 모델의 복잡도와 관련된 편향과 분산사이의 트레이드 오프에서 적절한 지점을 확인할 수 있다.
3. 학습곡선 플롯을 이용하면 훈련집합의 크기에 따른 훈련 점수와 검증 점수의 변화를 시각적으로 확인할 수 있다.
4. 그리드 서치 자동화 도구를 이용하면 검증 점수를 최대화 하는 최적의 모델을 찾아 데이터에 적합시킬 수 있다.
5. 특징 공학을 통해 머신러닝의 특징 행렬을 구축하는데 필요한 범주형 데이터의 인코딩, 복잡도를 증가시키기 위한 유도 특징의 추가, 누락데이터 대체 등의 작업을 수행하며, 파이프 라인을 통해 작업의 생산성을 높일수 있다.