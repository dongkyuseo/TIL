# 머신러닝 교차검증

1. 교차검증의 필요성과 절차 및 기법에 대해 살핌
2. 검증곡선과 학습곡선의 특징 이해
3. 최적의 모델을 찾기 위한 그리드서치 사용법 확인
4. 특징공학을 이용한 특징 변환 기법 살펴보기

## 교차 검증

- 교차검증의 기본절차와 필요성
- 교차검증의 기본절차
  1. 교차 검증의1 단계에서는 데이터를 학습용과 테스트용으로 나눔
  2. 모델의 테스트 성능을 기록
  3. 교차 거증의 매 단계마다 다른 파티션으로 위의 작업을 수행 #모든 데이터를 학습 및 테스트 할 수 있음
  4. 모델의 최종 성능은 매 단계의 테스트 성능을 평균 계산
- 교차 검증은 모델의 변동성을 줄여주며 오버피팅과 같은 문제를 막아줌

- k폴드(겹) 교차 거검증
  - 데이터를 무작위로 k개의 동일한 크기인 폴드로 나눔(보통  k 값으로 3, 5, 10 을 많이 사용)
  - 각 시행 단계에서 특정 폴드를 테스트용으로, 나머지는 학습용으로 사용
  - 각 폴드를 테스트 세트로 한 번씩 사용하고 이 과정을 k번 반복 시행함
  - 최종적으로 모델 성능의 평균을 계산

- 단일 관측치 제거 방식(LOOCV)
  - 검증을 시행할 때마다 한 지점을 제외한 모든 지점에서 훈련(scikitlearn에서 지원되는 기능)
  - Leav-one-out cross validation
  - 매 시행 단계에서 테스트 샘플을 고정하는 방식
  - 데이터를 n개의 서브세트로 분할하고, n개 중 1개를 테스트용으로 두고 n-1개로 학습을 수행
  - 데이터 크기가 n이면 n번의 교차 검증을 수행(데이터의 크기가 중요함)



## 최적의 모델

- 모델의 성능이 기대에 못미칠 경우 어떻게 개선할 것인가? (정답은 없음)
  - 더 복잡하거나 더 유연한 모델을 사용
  - 덜 복잡하거나 덜 유연한 모델을 사용
  - 더 많은 훈련 표본을 수집
  - 각 표본에 특징을 추가하기 위해 더 많은 데이터를 수집



## 편향-분산 트레이드 오프

- 언더피트(고편향 모델) : 과소적합. 모델이 고편향됨, 모델이 모든 특징을 적절히 설명할 수 있을 만큼 모델 유연성이 충분치 않음
- 오버피트(고분산 모델) : 과대적합. 모델이 고분산됨. 모델이 모든 특징을 세밀하게 설명할 수 있을 만큼 모델 유연성이 충분하지만, 훈련데이터의 잡음까지 반영하고 있음



## 검증곡선

- 편향과 분산 사이의 트레이드오프에서 가장 효율적인 지점 -> **최적의 모델**을 찾을 수 있음



## 학습곡선

- 최적의 모델은 훈련데이터의 규모에도 의존함
- 검증곡선은 데이터의 규모가 증가하면 그래프가 바뀜
- 학습곡선 : 훈련집합의 크기에 따른 훈련 점수/검증 점수의 플롯
  - 트레이닝 스코어와 검증곡선이 수렴한단는 것은 **데이터의 규모가 커져도 개선의 효과를 보이지 않는 지점** 이라는 의미
  - 더 복잡한 모델로 변경 : 단, 학습스코어와 검증스코어의 편차를 감수해야 함
  - 빅데이터가 머신러닝에서 기술적으로 훌륭한 자원이 됨



## 그리드 서치

- 최적의 다항식 모델을 구하기 위한 GridSearchCV
- 그리드서치 : 검증점수를 최대화 하는 모델을 찾아내는 자동화 도구





























