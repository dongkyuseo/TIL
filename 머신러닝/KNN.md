# KNN k-최근접 이웃 알고리즘 개념

- 분류나 회귀에 사용할 수 있는 알고리즘으로 단순해 보이지만 강력하고 유용한 기법
- 비매개변수 머신러닝 모델(훈련 인스턴스를 내장하여, 테스트인스턴스와 비교함)
- 훈련 단계에서 학습을 하지 않기 때문에 "게으른 학습"이라 부름
- 테스트/ 검증 단계에서 테스트 관측값과 가장 근겆합 훈련 관측 값을 비교
- 거리에만 의존하므로 차원의 저주에 따라 예측에 필요한 개수가 늘어마녀 성능이 크게 저하됨



## KNN 특징

- 유클리드 공간의 점과 점사이의 직선거리 사용

- 2차원 공간의 유클리드 거리 계산 방법

- k개의 가장 가까운 훈련 인스턴스를 골라 가장 많은 레이블을 분류로 선택

- 특징의 표준화된 크기 조절(스케일링)이 필요 (거리를 사옹하기에 스케일링이 중요)

  standardscaler = 표준점수를 만들어줌



## 차원의 저주

- 차원과 거리는 비례관계
- 차원이 늘어나고 거리가 늘어나면 복잡해짐
- 1차원으로 표현하는 것과 2차원으로 표현하면 거리가 늘어나고 차원이 더 늘어나면 거리가 더 멀어짐
- 차원 증가시 분류기 작동이 어려워짐

## 주요내용 정리

1. k-최근적 이웃은 비매개변수 머신러닝 모델로 훈련 단계에서 학습을 하지 않기 때문에 "게으른 학습"이라 불림, 테스트/검증 단계에서 테스트 관측값과 가장 근저한 훈련 관측값을 비교 작업을 수행한다
2. k-최근접 이웃은 거리에만 의존하므로 차원의 저주에 의해 예측에 필요한 특징의 개수가 늘어나면 성능이 크게 저하 됨
3. k-최근접 이웃 분류기의 성능측정은 혼동행렬을 이용해 정확도, AUC와 같은 다양한 평가지표를 활용할 수 있다.
4. 그리드 서치를 이용해 n_neighbor와 같은 k-최근접 이웃 하이퍼파라미터의 최적값을 찾아낼 수 있다.

