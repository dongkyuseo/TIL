# 특성공학

key words : #특성선택 #특성추출 #Filter방식 #Wrapper방식 #차원축소법#주성분분석(PCA)
#특이값분해(SVD)



## 특성공간 차원 축소의 필요성

- 모델의해석력향상. 
- 모델훈련시간의단축. 
- 차원의저주방지. : 
- 과적합(overfitting)에의한일반화오차를줄여성능향상.

## 특성공학의 방법론은 크게 

## 특성선택(feature selection)방법과 

## 특성추출(feature extraction)방법 으로 구분 할 수 있음.



## 특성 선택 방법론

- 주어진특성변수들가운데가장좋은특성변수의조합만선택함.
- 불필요한특성변수를제거함.
- Filtering, Wrapper, Embedded 방식으로분류할수있음
  - Filtering : 각 특성변수를 독립적인 평가함수로 평가함, 각 특성변수와 목표변수와의 연고나성을 측정한 뒤 목표변수를 잘 설명할수 있는 특성변수만을 선택하는 방식, 1:1 관계로 연관성을 판단함(p-value 사용가능), 변수를 연관성이 높은순으로 랭킹을 매겨 랭킹이 높은 상위의 몇개의 변수만을 선택하는 방식, 속도가빠름
  - Wrapper : (후보군을 모델에 집어넣고 결과를 평가함) 반복하여 최고의 조합을 찾아냄, 특성변수에 중복된 정보가 많을경우 이를 효과적으로 제거함. 특성변수의 조합을 이용해 평가를 함. 시간과 비용이 오래걸림(모든 방법론을 확인해 보는것).
  - Embedded : 모델이 알아서 변수를 선택해서 결과를 보여주는 모델, 학습과정에 최적화된 변수를 선택함. 특성변수 파라미터에 규제를 가함

![image-20211009141440391](C:/Users/DQ/AppData/Roaming/Typora/typora-user-images/image-20211009141440391.png)



## 특성추출법

### 주성분분석(PCA)

- 서로 연관되어 있는 변수들(𝑥1,...,𝑥𝑘)이 관찰 되었을때, 이 변수들이 전체적으로 가지고 있는 정보들을 최대한 확보하는 적은수의 새로운 변수(주성분, PC)를 생성하는 방법.
- 목적
  - 자료에서 변동이 큰 축을 탐색함.
  - 변수들에 담긴 정보의 손실을 최소화 하면서 차원을 축소함.
  - 서로 상관이 없거나 독립적인 새로운 변수인 주성분을 통해 데이터의 해석을 용이하게 함.
- 주성분 분석에 관한 기하학적 의미
  - 주성분축은 원래변수들의 좌표축이 직교 회전 변환된 것으로 해석할 수 있음.
  - 1. 첫번째 주성분 축은 데이터의 변동이 가장 커지는 축임.
    2. 자료들의 공분산행렬이 대각 행렬이 되도록 회전한 것으로 해석할 수 있음.
    3. 두번째 주성분 축은 첫번째 주성분 축과 직교하며 첫번째 주성분축 다음으로 데이터의 변동이 큰 축을 나타냄.
    4. 각 관찰치별 주성분 점수는 대응하는 원자료값들의 주성분 좌표축에서의 좌표값에 해당함.

### 특성값분해(SVD)

- 특성값 분해 이론 : 특이값분해(임의이 크기를 가진 행렬을 3개의 곱으로 표현함.)
- 주성분분석(PCA)와 특성값분해의 관계
  - 𝐴의 오른쪽 특성벡터는 𝐴의 공분산행렬의 고유벡터와 동일함.
  - 자료행렬에 대한 특성값 분해로 주성분을 도출 가능.

